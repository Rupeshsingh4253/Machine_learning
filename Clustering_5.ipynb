{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. A contingency matrix, also known as a contingency table or cross-tabulation, is a tabular representation of the\n",
    "relationships between two categorical variables. It displays the frequency distribution of observations for each combination\n",
    "of categories of the two variables. In the context of evaluating the performance of a classification model, a contingency \n",
    "matrix compares the predicted classes of the model with the true classes in the dataset. It helps assess the model's accuracy, \n",
    "precision, recall, and other performance metrics by providing counts of true positives, false positives, true negatives, and\n",
    "false negatives.\n",
    "\n",
    "Q2. A pair confusion matrix is a variation of a regular confusion matrix that focuses on pairs of categories rather than \n",
    "individual classes. It provides a detailed breakdown of the confusion between pairs of classes, showing the frequency of each \n",
    "possible pair of predicted and true classes. Pair confusion matrices can be useful in situations where the classification task\n",
    "involves distinguishing between specific pairs of classes or when analyzing the performance of a model on specific categories\n",
    "of interest.\n",
    "\n",
    "Q3. In natural language processing (NLP), an extrinsic measure is a performance metric that evaluates the performance of a \n",
    "language model based on its performance in downstream tasks or applications. These tasks could include sentiment analysis, \n",
    "named entity recognition, machine translation, and others. Extrinsic measures assess how well the language model performs in\n",
    "real-world applications by measuring its impact on task performance or user experience.\n",
    "\n",
    "Q4. An intrinsic measure in machine learning refers to a performance metric that evaluates the quality of a model based solely\n",
    "on its performance on a specific task or dataset without considering its impact on downstream applications. Unlike extrinsic\n",
    "measures, which assess a model's performance in real-world contexts, intrinsic measures focus on the model's performance in \n",
    "isolation. Examples of intrinsic measures include accuracy, precision, recall, F1 score, and others.\n",
    "\n",
    "Q5. The purpose of a confusion matrix in machine learning is to provide a detailed breakdown of the performance of a \n",
    "classification model by summarizing the counts of true positives, false positives, true negatives, and false negatives for each\n",
    "class in the dataset. It helps identify the strengths and weaknesses of the model by revealing which classes are well-predicted\n",
    "and which ones are frequently misclassified. Additionally, a confusion matrix allows for the calculation of various performance\n",
    "metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Q6. Common intrinsic measures used to evaluate the performance of unsupervised learning algorithms include:\n",
    "\n",
    "Silhouette Score: Measures the quality of clusters by computing the mean distance between data points in the same cluster\n",
    "    compared to the mean distance between data points in different clusters. A higher silhouette score indicates better cluster\n",
    "    separation and cohesion.\n",
    "Davies-Bouldin Index: Measures the average similarity between each cluster and its most similar cluster relative to the average\n",
    "    dissimilarity within clusters. Lower values indicate better clustering.\n",
    "Calinski-Harabasz Index: Measures the ratio of between-cluster dispersion to within-cluster dispersion, with higher values\n",
    "    indicating better clustering.\n",
    "These measures help assess the quality of clusters produced by unsupervised learning algorithms and provide insights into the \n",
    "cohesion, separation, and overall structure of the data.\n",
    "\n",
    "Q7. Limitations of using accuracy as a sole evaluation metric for classification tasks include:\n",
    "\n",
    "Accuracy does not account for class imbalances in the dataset, leading to misleading results when classes are unevenly\n",
    "distributed.\n",
    "Accuracy treats all misclassifications equally, whereas in many applications, some types of errors may be more costly or \n",
    "significant than others.\n",
    "Accuracy does not provide insights into the specific types of errors made by the model, making it challenging to diagnose and \n",
    "address weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
