{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Bayes' theorem is a fundamental theorem in probability theory named after Thomas Bayes.\n",
    "It describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "Q3. Bayes' theorem is used in practice in various fields such as machine learning, statistics, and medical diagnosis.\n",
    "In machine learning, it's commonly used in Bayesian inference, where it helps in making predictions and updating beliefs \n",
    "based on new evidence. It's also used in spam filtering, document classification, and in estimating the parameters \n",
    "of statistical models.\n",
    "\n",
    "Q4. Bayes' theorem provides a way to calculate conditional probabilities. \n",
    "It shows how the probability of an event (A) occurring given the occurrence of another event (B) is related to the\n",
    "probability of the second event occurring given the first event, along with the individual probabilities of each event.\n",
    "\n",
    "Q5. The choice of which type of Naive Bayes classifier to use depends on the nature of the features and \n",
    "the assumptions about their distribution. \n",
    "The three common types of Naive Bayes classifiers are:\n",
    "Gaussian Naive Bayes: Assumes that continuous features follow a Gaussian (normal) distribution.\n",
    "Multinomial Naive Bayes: Suitable for features that represent counts or frequencies of occurrences, typically used in text \n",
    "classification with word counts.\n",
    "Bernoulli Naive Bayes: Assumes that features are binary variables (occurring or not occurring), commonly used in document \n",
    "classification tasks with binary feature vectors.\n",
    "The choice depends on whether the features are continuous or discrete and whether they follow a specific distribution.\n",
    "\n",
    "Q6. To predict the class of a new instance using Naive Bayes, we calculate the posterior probability of each class\n",
    "given the features of the new instance and choose the class with the highest probability.\n",
    "In this case, we would calculate the posterior probability of classes A and B given the features X1 = 3 and X2 = 4, and\n",
    "choose the class with the highest probability. Since equal prior probabilities are assumed, we only need to compare the \n",
    "likelihoods of the features given each class. Using the provided table, we would calculate the likelihoods of X1 = 3 and\n",
    "X2 = 4 for classes A and B, and choose the class with the highest product of likelihoods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
